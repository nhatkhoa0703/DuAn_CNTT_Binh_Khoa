{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading raw review data...\n",
      "Original dataset shape: (2173, 6)\n",
      "\n",
      "üîç First few rows:\n",
      "   review_id                            place_name       author  rating  \\\n",
      "0          1  Qu√°n ƒÇn Hu·∫ø O Xu√¢n ·ªü Qu·∫≠n 1, TP. HCM      Thao Le     1.2   \n",
      "1          2  Qu√°n ƒÇn Hu·∫ø O Xu√¢n ·ªü Qu·∫≠n 1, TP. HCM  Thao Nguyen     6.0   \n",
      "2          3  Qu√°n ƒÇn Hu·∫ø O Xu√¢n ·ªü Qu·∫≠n 1, TP. HCM  Thanh Trang     6.4   \n",
      "3          4  Qu√°n ƒÇn Hu·∫ø O Xu√¢n ·ªü Qu·∫≠n 1, TP. HCM    MIMI TR·∫¶N     8.0   \n",
      "4          5  Qu√°n ƒÇn Hu·∫ø O Xu√¢n ·ªü Qu·∫≠n 1, TP. HCM        Quynh     6.0   \n",
      "\n",
      "        date                                               text  \n",
      "0  7/20/2022  1.2 Qu√°n ph·ª•c v·ª• k√©m, √¥ng ch·ªß ng·ªìi thu ti·ªÅn ƒëu...  \n",
      "1  1/16/2021  6.0 H∆°i m·∫Øc!!! Ph·∫ßn b√∫n b√≤ kh√¥ng ƒë∆∞·ª£c 3 l√°t b√≤...  \n",
      "2  7/22/2020  6.4 ƒÇn ƒë∆∞·ª£c L∆∞·ªõt Now th·∫•y qu√°n n√†y c√≥ Deal gi·∫£...  \n",
      "3  4/19/2020  8.0 Qu√°n ƒÇn Hu·∫ø O Xu√¢n ƒÇn ·ªü ƒë√¢y th√¨ ch·ªâ ƒÉn c√°c...  \n",
      "4  2/23/2020  6.0 M√≥n Hu·∫ø C√°c lo·∫°i b√°nh Hu·∫ø ngon, n∆∞·ªõc m·∫Øm ·ªï...  \n",
      "\n",
      "üìè Reviews with valid length: 2087/2173\n",
      "üìù Reviews with reasonable text ratio: 2171/2173\n",
      "\n",
      "‚ú® Final cleaned dataset: 2085 reviews (from 2173 original)\n",
      "\n",
      "üîç Examples of cleaned reviews:\n",
      "\n",
      "Example 1:\n",
      "BEFORE: 1.2 Qu√°n ph·ª•c v·ª• k√©m, √¥ng ch·ªß ng·ªìi thu ti·ªÅn ƒëu·ªïi kh√°ch Qu√°n ph·ª•c v·ª• k√©m, √¥ng ch·ªß ng·ªìi thu ti·ªÅn ƒëu·ªïi ...\n",
      "AFTER:  Qu√°n ph·ª•c v·ª• k√©m, √¥ng ch·ªß ng·ªìi thu ti·ªÅn ƒëu·ªïi kh√°ch Qu√°n ph·ª•c v·ª• k√©m, √¥ng ch·ªß ng·ªìi thu ti·ªÅn ƒëu·ªïi kh√°c...\n",
      "\n",
      "Example 2:\n",
      "BEFORE: 6.0 H∆°i m·∫Øc!!! Ph·∫ßn b√∫n b√≤ kh√¥ng ƒë∆∞·ª£c 3 l√°t b√≤ nh∆∞ h√¨nh. H∆°i b·ªã m·∫Øc v√† √≠t. Con g√°i nh∆∞ m√¨nh c√≤n c·∫£m ...\n",
      "AFTER:  H∆°i m·∫Øc! Ph·∫ßn b√∫n b√≤ kh√¥ng ƒë∆∞·ª£c 3 l√°t b√≤ nh∆∞ h√¨nh. H∆°i b·ªã m·∫Øc v√† √≠t. Con g√°i nh∆∞ m√¨nh c√≤n c·∫£m th·∫•y k...\n",
      "\n",
      "Example 3:\n",
      "BEFORE: 6.4 ƒÇn ƒë∆∞·ª£c L∆∞·ªõt Now th·∫•y qu√°n n√†y c√≥ Deal gi·∫£m ph·∫ßn b√°nh b√®o Hu·∫ø th·∫≠p c·∫©m nh∆∞ h√¨nh c√≤n 10K thui m√† ...\n",
      "AFTER:  Qu√°n ƒÇn Hu·∫ø O Xu√¢n ƒÇn ·ªü ƒë√¢y th√¨ ch·ªâ ƒÉn c√°c m√≥n sau l√† b√∫n m·∫Øm n√™m, nem n∆∞·ªõng, b√°nh b√†o. T·∫•t c·∫£ ƒë·ªÅu n...\n",
      "\n",
      "üíæ Cleaned data saved to: ../duancntt/cleaned_reviews.csv\n",
      "\n",
      "üìä CLEANING SUMMARY:\n",
      "Original reviews: 2173\n",
      "After cleaning: 2085\n",
      "Removal rate: 4.0%\n",
      "\n",
      "Review length distribution:\n",
      "Average length: 315 characters\n",
      "Median length: 261 characters\n",
      "Min length: 12\n",
      "Max length: 992\n",
      "\n",
      "Rating distribution:\n",
      "rating\n",
      "1.0     139\n",
      "1.2       6\n",
      "1.4       5\n",
      "1.6       2\n",
      "1.8      12\n",
      "2.0      10\n",
      "2.2      11\n",
      "2.4       9\n",
      "2.6      23\n",
      "2.8      21\n",
      "3.0      21\n",
      "3.2      12\n",
      "3.4      44\n",
      "3.6      15\n",
      "3.8      17\n",
      "4.0      17\n",
      "4.2      50\n",
      "4.4      23\n",
      "4.6      20\n",
      "4.8       9\n",
      "5.0     113\n",
      "5.2       9\n",
      "5.4       9\n",
      "5.6       9\n",
      "5.8      22\n",
      "6.0      41\n",
      "6.2      29\n",
      "6.4      21\n",
      "6.6      32\n",
      "6.8      44\n",
      "7.0     129\n",
      "7.2      80\n",
      "7.4      78\n",
      "7.6      89\n",
      "7.8      83\n",
      "8.0     120\n",
      "8.2      89\n",
      "8.4      63\n",
      "8.6      57\n",
      "8.8      44\n",
      "9.0      69\n",
      "9.2      29\n",
      "9.4      34\n",
      "9.6      44\n",
      "9.8      39\n",
      "10.0    243\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Vietnamese Restaurant Review Data Cleaning\n",
    "# This notebook cleans the raw scraped data and prepares it for labeling\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Load the raw data\n",
    "print(\"üìä Loading raw review data...\")\n",
    "df = pd.read_csv('../duancntt/foody_reviews_multi.csv', encoding='utf-8')\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(\"\\nüîç First few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# === CLEANING STEP 1: Remove rating numbers from text ===\n",
    "def clean_rating_from_text(text):\n",
    "    \"\"\"Remove rating numbers like '1.2', '6.0', '8.0' from the beginning of text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    # Remove patterns like \"1.2 \", \"6.0 \", \"8.0 \" from the start\n",
    "    text = re.sub(r'^[\\d\\.]+\\s+', '', str(text))\n",
    "    return text.strip()\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(clean_rating_from_text)\n",
    "\n",
    "# === CLEANING STEP 2: Remove \"...Xem th√™m\" and similar endings ===\n",
    "def remove_truncation_markers(text):\n",
    "    \"\"\"Remove truncation markers like '...Xem th√™m', '...Read more'\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    # Common truncation patterns in Vietnamese reviews\n",
    "    truncation_patterns = [\n",
    "        r'\\.{3,}Xem th√™m$',\n",
    "        r'\\.{3,}$',\n",
    "        r'\\s*‚Ä¶\\s*$',\n",
    "        r'\\.{2,}\\s*$'\n",
    "    ]\n",
    "    \n",
    "    for pattern in truncation_patterns:\n",
    "        text = re.sub(pattern, '', str(text), flags=re.IGNORECASE)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(remove_truncation_markers)\n",
    "\n",
    "# === CLEANING STEP 3: Filter out very short or very long reviews ===\n",
    "def is_valid_review_length(text):\n",
    "    \"\"\"Check if review has reasonable length (10-1000 characters)\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    return 10 <= len(str(text)) <= 1000\n",
    "\n",
    "# Filter reviews by length\n",
    "df['is_valid_length'] = df['cleaned_text'].apply(is_valid_review_length)\n",
    "print(f\"\\nüìè Reviews with valid length: {df['is_valid_length'].sum()}/{len(df)}\")\n",
    "\n",
    "# === CLEANING STEP 4: Remove reviews with too many special characters ===\n",
    "def has_reasonable_text_ratio(text):\n",
    "    \"\"\"Check if text has reasonable ratio of Vietnamese characters vs. special chars\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    \n",
    "    text = str(text)\n",
    "    # Count Vietnamese letters, numbers, and basic punctuation\n",
    "    vietnamese_chars = re.findall(r'[a-zA-Z√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µ√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªá·ªÉ·ªÖ√¨√≠·ªã·ªâƒ©√≤√≥·ªç·ªè√µ√¥·ªì·ªë·ªô·ªï·ªó∆°·ªù·ªõ·ª£·ªü·ª°√π√∫·ª•·ªß≈©∆∞·ª´·ª©·ª±·ª≠·ªØ·ª≥√Ω·ªµ·ª∑·ªπƒëƒê0-9\\s.,!?]', text)\n",
    "    \n",
    "    if len(text) == 0:\n",
    "        return False\n",
    "    \n",
    "    ratio = len(vietnamese_chars) / len(text)\n",
    "    return ratio > 0.7  # At least 70% should be normal characters\n",
    "\n",
    "df['has_reasonable_text'] = df['cleaned_text'].apply(has_reasonable_text_ratio)\n",
    "print(f\"üìù Reviews with reasonable text ratio: {df['has_reasonable_text'].sum()}/{len(df)}\")\n",
    "\n",
    "# === CLEANING STEP 5: Normalize text (optional cleanup) ===\n",
    "def normalize_text(text):\n",
    "    \"\"\"Basic text normalization\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Replace multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Replace multiple punctuation with single\n",
    "    text = re.sub(r'[!]{2,}', '!', text)\n",
    "    text = re.sub(r'[?]{2,}', '?', text)\n",
    "    text = re.sub(r'[.]{3,}', '...', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "df['normalized_text'] = df['cleaned_text'].apply(normalize_text)\n",
    "\n",
    "# === FILTERING: Keep only good quality reviews ===\n",
    "quality_filter = (\n",
    "    df['is_valid_length'] & \n",
    "    df['has_reasonable_text'] & \n",
    "    df['normalized_text'].notna()\n",
    ")\n",
    "\n",
    "cleaned_df = df[quality_filter].copy()\n",
    "print(f\"\\n‚ú® Final cleaned dataset: {len(cleaned_df)} reviews (from {len(df)} original)\")\n",
    "\n",
    "# === PREPARE FINAL DATASET ===\n",
    "final_df = cleaned_df[[\n",
    "    'review_id', 'place_name', 'author', 'rating', 'date', 'normalized_text'\n",
    "]].copy()\n",
    "\n",
    "final_df.rename(columns={'normalized_text': 'clean_text'}, inplace=True)\n",
    "\n",
    "# Show some examples of the cleaning results\n",
    "print(\"\\nüîç Examples of cleaned reviews:\")\n",
    "for i in range(min(3, len(final_df))):\n",
    "    original = df.iloc[i]['text'][:100] + \"...\" if len(str(df.iloc[i]['text'])) > 100 else df.iloc[i]['text']\n",
    "    cleaned = final_df.iloc[i]['clean_text'][:100] + \"...\" if len(final_df.iloc[i]['clean_text']) > 100 else final_df.iloc[i]['clean_text']\n",
    "    \n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"BEFORE: {original}\")\n",
    "    print(f\"AFTER:  {cleaned}\")\n",
    "\n",
    "# === SAVE CLEANED DATA ===\n",
    "output_path = '../duancntt/cleaned_reviews.csv'\n",
    "final_df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "print(f\"\\nüíæ Cleaned data saved to: {output_path}\")\n",
    "\n",
    "# === DATA QUALITY STATISTICS ===\n",
    "print(f\"\\nüìä CLEANING SUMMARY:\")\n",
    "print(f\"Original reviews: {len(df)}\")\n",
    "print(f\"After cleaning: {len(final_df)}\")\n",
    "print(f\"Removal rate: {((len(df) - len(final_df)) / len(df) * 100):.1f}%\")\n",
    "\n",
    "print(f\"\\nReview length distribution:\")\n",
    "lengths = final_df['clean_text'].str.len()\n",
    "print(f\"Average length: {lengths.mean():.0f} characters\")\n",
    "print(f\"Median length: {lengths.median():.0f} characters\")\n",
    "print(f\"Min length: {lengths.min()}\")\n",
    "print(f\"Max length: {lengths.max()}\")\n",
    "\n",
    "print(f\"\\nRating distribution:\")\n",
    "print(final_df['rating'].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f996aea4fd693da46e53ef49f1c41c11572408c4a464598b49539e6687a0e87d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
